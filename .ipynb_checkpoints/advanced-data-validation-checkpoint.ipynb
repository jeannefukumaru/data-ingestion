{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeanne/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/jeanne/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeanne/anaconda3/lib/python3.6/site-packages/mxnet/gluon/data/vision.py:118: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  label = np.fromstring(fin.read(), dtype=np.uint8).astype(np.int32)\n",
      "/Users/jeanne/anaconda3/lib/python3.6/site-packages/mxnet/gluon/data/vision.py:122: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  data = np.fromstring(fin.read(), dtype=np.uint8)\n"
     ]
    }
   ],
   "source": [
    "def transform(data, label):\n",
    "    return mx.nd.transpose(data.astype(np.float32), (2,0,1))/255, label.astype(np.float32)\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.FashionMNIST(train=True, transform=transform), batch_size=128, shuffle=True)\n",
    "\n",
    "validation_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.FashionMNIST(train=False, transform=transform), batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildCNN(cnnlayers, fclayers=([256,''],[64,'']), outputs=10, activation='relu', alpha=0.01):\n",
    "    net = gluon.nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        for l in cnnlayers:                \n",
    "            if (l[0]<1.0):\n",
    "                net.add(gluon.nn.Dropout(l[0]))\n",
    "            else:\n",
    "                net.add(gluon.nn.Conv2D(channels=l[0], kernel_size=l[1], padding=l[2], activation=None))\n",
    "                if (l[5]=='BN'):\n",
    "                    net.add(gluon.nn.BatchNorm(axis=1, center=True, scale=True))\n",
    "                if (activation=='leakyrelu'):\n",
    "                    net.add(gluon.nn.LeakyReLU(alpha=alpha))\n",
    "                else:\n",
    "                    net.add(gluon.nn.Activation(activation=activation))\n",
    "                net.add(gluon.nn.MaxPool2D(pool_size=l[4], strides=l[4]))\n",
    "                \n",
    "        net.add(gluon.nn.Flatten())\n",
    "        \n",
    "        for l in fclayers:\n",
    "            if (l[0]<1.0):\n",
    "                net.add(gluon.nn.Dropout(l[0]))\n",
    "            else:\n",
    "                net.add(gluon.nn.Dense(l[0], activation=None))\n",
    "                if (l[1]=='BN'):\n",
    "                    net.add(gluon.nn.BatchNorm(axis=1, center=True, scale=True))\n",
    "                if (activation=='leakyrelu'):        \n",
    "                    net.add(gluon.nn.LeakyReLU(alpha=alpha))\n",
    "                else:\n",
    "                    net.add(gluon.nn.Activation(activation=activation))\n",
    "            \n",
    "        net.add(gluon.nn.Dense(outputs))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(net, optimizer='sgd', learning_rate=0.1, weight_decay=1e-6):\n",
    "    net.collect_params().initialize(mx.init.Xavier(magnitude=2.24))\n",
    "    trainer = gluon.Trainer(net.collect_params(), \n",
    "                            optimizer, \n",
    "                            {'learning_rate': learning_rate, 'wd': weight_decay})\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data_iterator, net,ctx=mx.cpu()):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    for (data, label) in data_iterator:\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        predictions = mx.nd.argmax(output, axis=1)\n",
    "        acc.update(preds=predictions, labels=label)\n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainer, train_data, validation_data, epochs, ctx=mx.cpu()):\n",
    "    training_accuracies = []\n",
    "    validation_accuracies = []\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    for e in range(epochs):\n",
    "        tic = time.time()\n",
    "        for (data, label) in train_data:\n",
    "            data  = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net(data)\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "                loss.backward()\n",
    "            trainer.step(data.shape[0])\n",
    "        toc = time.time()\n",
    "        train_accuracy = accuracy(train_data, net)\n",
    "        training_accuracies.append(train_accuracy)\n",
    "        validation_accuracy = accuracy(validation_data, net)\n",
    "        validation_accuracies.append(validation_accuracy)\n",
    "        print(\"Epoch#%d Time=%.2f Training=%.4f Validation=%.4f Diff=%.4f\" \n",
    "              % (e, toc-tic, train_accuracy, validation_accuracy, train_accuracy-validation_accuracy))\n",
    "    return training_accuracies, validation_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2D(None -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Activation(relu)\n",
      "  (2): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  (3): Conv2D(None -> 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (4): Activation(relu)\n",
      "  (5): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  (6): Flatten\n",
      "  (7): Dense(None -> 256, linear)\n",
      "  (8): Activation(relu)\n",
      "  (9): Dense(None -> 64, linear)\n",
      "  (10): Activation(relu)\n",
      "  (11): Dense(None -> 10, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "# 1x28x28 -CONV-> 64x28x28 -POOL-> 64x13x13 -CONV-> 64x10x10 -POOL-> 64x5x5 --> 1600 -FC-> 256 -FC-> 64 -FC-> 10\n",
    "net = buildCNN(([64,3,1,2,2,''],[64,3,0,2,2,'']))\n",
    "print(net)\n",
    "trainer = init(net)\n",
    "training_accuracies, validation_accuracies = train(net, trainer, train_data, validation_data, epochs)\n",
    "plot_accuracies(training_accuracies, validation_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "net = buildCNN(([64,3,1,2,2,''],[64,3,0,2,2,'']))\n",
    "print(net)\n",
    "trainer = init(net, optimizer='adam', learning_rate=1e-3)\n",
    "training_accuracies, validation_accuracies = train(net, trainer, train_data, validation_data, epochs)\n",
    "plot_accuracies(training_accuracies, validation_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "net = buildCNN(([64,3,1,2,2,'BN'],[64,3,0,2,2,'BN']), ([256,'BN'], [64,'BN']))\n",
    "print(net)\n",
    "trainer = init(net, optimizer='adam', learning_rate=1e-3)\n",
    "training_accuracies, validation_accuracies = train(net, trainer, train_data, validation_data, epochs)\n",
    "plot_accuracies(training_accuracies, validation_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "net = buildCNN(([64,3,1,2,2,'BN'],[0.3],[64,3,0,2,2,'BN'],[0.3]), ([256,'BN'],[0.3],[64,'BN'],[0.3]))\n",
    "print(net)\n",
    "trainer = init(net, optimizer='adam', learning_rate=1e-3)\n",
    "training_accuracies, validation_accuracies = train(net, trainer, train_data, validation_data, epochs)\n",
    "plot_accuracies(training_accuracies, validation_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "net = buildCNN(([64,3,1,2,2,'BN'],[0.5],[64,3,0,2,2,'BN'],[0.5]), ([256,'BN'],[0.5],[64,'BN'],[0.5]))\n",
    "print(net)\n",
    "trainer = init(net, optimizer='adam', learning_rate=1e-3)\n",
    "training_accuracies, validation_accuracies = train(net, trainer, train_data, validation_data, epochs)\n",
    "plot_accuracies(training_accuracies, validation_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.MNIST(train=True, transform=transform), batch_size=128, shuffle=True)\n",
    "\n",
    "validation_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.MNIST(train=False, transform=transform), batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "net = buildCNN(([64,3,1,2,2,'BN'],[0.3],[64,3,0,2,2,'BN'],[0.3]), ([256,'BN'],[0.3],[64,'BN'],[0.3]))\n",
    "print(net)\n",
    "trainer = init(net, optimizer='adam', learning_rate=1e-3)\n",
    "training_accuracies, validation_accuracies = train(net, trainer, train_data, validation_data, epochs)\n",
    "plot_accuracies(training_accuracies, validation_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
